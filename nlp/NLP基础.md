# NLP基础

## 计量学三大基础

### 洛特卡定律

 洛特卡定律描述了科学领域中作者的生产率分布，二八定律，少数的作者贡献了大多量文献，多数作者只贡献少量文献。
$$
f(x)=\frac{C}{x^2} \tag{1.1}
$$
其中:

* $f(x)$: 作者生产$x$篇文章的概率 

* $x$: 作者的生产率（文章数）
* $C$: 归一化系数，用以使概率和为1
* $n$: 幂指数，通常为1 即$f(x)\sim (\frac{1}{x^2})$

### 齐夫定律

齐夫定律描述了自然语言中的词频分布，即一个单词出现的频率与它在频率表里的排名成反比。所以，频率最高的单词出现的频率大约是出现频率第二位的单词的2倍，而出现频率第二位的单词则是出现频率第四位的单词的2倍。齐夫定律可应用与自然语言中的词表构建与文本数据压缩稀疏化处理
$$
f(r)=\frac{C}{r^s} \tag{1.2}
$$
其中：

- $f(r)$：排名为 $r$ 的词语的频率。
- $r$：词语的排名（按频率从高到低排序）。
- $C$：归一化常数。
- $s$：幂指数，通常接近 1。

### 布拉特福德定律

布拉德福定律描述了文献分布的核心区和外围区，即少数核心期刊涵盖了大部分的高价值文献，而大部分期刊只包含少量文献。布拉特福德定律可用于检索领域核心资源的优先级设定。
$$
N=klog(1+mR)
$$
其中：

- $N$：文献数量。
- $R$：核心区域的文献数倍数。
- $k$,$m$：经验常数，依赖于具体的数据分布。

## 语法句法分析

## SAO

## 基于机器学习的NLP

### 特征工程



## 基于深度学习的NLP

### word2vec



### textCNN

### transformer

#### position embedding

#### self-attention

#### ResNet

