# BM25:zzz:

BM25是一种用于信息检索的评分函数，基于词频（TF） 和 逆文档频率（IDF），用于计算查询 Q 与文档 D 的相关性。

:white_check_mark: ​BM25 是 TF-IDF 的改进版，它引入了**词频归一化（TF Normalization）** 和 **文档长度归一化**，解决了：

- **短文档得分偏低的问题**
- **高频词过度影响排名的问题**

:point_right: ​BM25的计算公式为：
$$
BM25(q,D)=\sum_{t\in q}^{}IDF(t)·\frac{f(t,D)·(k_1+1)}{f(t,D)+k_1·(1-b+b·\frac{|D|}{avgDL})}
$$



:white_check_mark: ​其中$q$是查询文本，$t$是$q$的分词(token),$f(t,D)$表示词$t$在文档$D$中的词频，$IDF(t)$是逆文档频率，$|D|$是文档$D$的长度，即总token。$avgDL$是文档集合$S(D)$的平均长度，$k_1,b$是超参数

:point_right: 逆文档频率IDF的计算公式为：
$$
IDF(t)=log(\frac{N-df+0.5}{df+0.5} + 1)
$$
:white_check_mark: 其中$N$是总文档数，$df$是包含词t的文档数

* **控制低频词的重要性：如果 t 在少数文档中出现（低 df），IDF 高，该词更重要。**
* **削弱高频词的影响：如果 t 在所有文档中都出现（高 df），IDF 低，该词影响力下降。**

:point_right: 词频归一化与文档长度归一化
$$
\frac{f(t,D)·(k_1+1)}{f(t,D)+k_1·(1-b+b·\frac{|D|}{avgDL})}
$$
:white_check_mark: $k_1$:**词频归一化参数**(通常 `1.2 ~ 2.0`), $b$：**文档长度归一化参数**(通常 `0.75`).

* 避免长文档得分过高：如果$|D|$ 很大（长文档），分母增大，$TF$ 降低，防止长文档得分偏高。$b$ 控制归一化程度(`b=0`时无归一化，`b=1`时完全归一化).
* 避免词频过大导致排名垄断：$TF$采用 非线性变换，防止某些高频词的影响过大。

:pencil: ​python实现简易BM25算法

```python
class BM25:
    def __init__(self, documents, k1=0.5, b=0.75):
        self.k1 = k1
        self.b = b
        self.documents = documents
        self.doc_len = [len(doc) for doc in documents]
        self.avgdl = sum(self.doc_len) / len(documents) if documents else 0
        self.doc_freqs = Counter(word for doc in documents for word in set(doc))

    @staticmethod
    def compute_idf(doc_freq, total_docs):
        # caculate idf
        return math.log((total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1)

    def score(self, document, query):
        score = 0.0
        doc_len = len(document)
        idfs = {
            word: self.compute_idf(self.doc_freqs[word], len(self.documents))
            for word in query
        }
        doc_freq = Counter(document)
        for word in query:
            if word in doc_freq:
                freq = doc_freq[word]
                idf = idfs.get(word, 0)
                denom = freq + self.k1 * (
                        1 - self.b + self.b * doc_len / self.avgdl
                )
                score += idf * freq * (self.k1 + 1) / denom
        return score
```























