# MindIE:zzz:

:question:如何在一台华为服务器(A800 t1 \ A800 t2)上进行LLM模型推理

## 安装华为驱动

:pushpin: ​首先需要根据服务器的型号安装对应的Npu驱动。你可以使用如下命令查看服务器的各硬件信息

:white_check_mark: ​查看NPU型号与服务器名称



```bash
npu-smi info
```

:white_check_mark: 查看cpu型号



```bash
lscpu
```



:white_check_mark: 查看系统版本



:pushpin: 接下来需要找到对应的Ascend驱动包进行安装。

## 安装MindIE

:pushpin: docker安装MindService

从华为官网Dockerhub下载对应的镜像文件，正常Docker启动即可。

## MindService启动推理模型

:pushpin: ​MindService通常位于路径/usr/local/Ascend/@下

进入目录/。@

修改conf目录下的配置文件config.json，配置参数详情参照华为官网https://www.hiascend.com/document/detail/zh/mindie/100/mindieservice/servicedev/mindie_service0285.html

修改完成后，启动bin目录下的启动脚本@，出现Successful后表示模型已经启动。可npu-smi info查看显存占用情况。

